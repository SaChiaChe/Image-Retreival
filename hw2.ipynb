{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Retrieval Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  Feature Database\n",
    "The features are generated offline, see GenerateFeautreDatabase.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"FeatureDatabase.pkl\",\"rb\") as f:\n",
    "    FeatureDatabase = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Experiments !\n",
    "Here, we experiment with all sort of features extracted <br>\n",
    "We calculate overall MAP and MAP for each category <br>\n",
    "\n",
    "*The result table and some findings are at the very bottom*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random - Null Hypothesis Test\n",
    "First, let's establish a null hypothesis to see if the methods below actually work <br>\n",
    "We randomly generate features for each image, thus, the query should be random as well <br>\n",
    "We get a pretty stable result around 0.04 overall MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 - MAP: 0.041509\n",
      "Best: nba_jersey(0.053166), baby_shoes(0.048646)\n",
      "Worst: chair(0.034581), garment(0.034623)\n",
      "Run 2 - MAP: 0.040547\n",
      "Best: cartoon_purse(0.054079), bracelet(0.052686)\n",
      "Worst: bicycle(0.032513), bottle(0.032546)\n",
      "Run 3 - MAP: 0.041753\n",
      "Best: korean_snack(0.053002), children_dress(0.051431)\n",
      "Worst: women_clothes(0.033087), sprite(0.033302)\n",
      "Run 4 - MAP: 0.041563\n",
      "Best: children_dress(0.067377), nba_jersey(0.055482)\n",
      "Worst: minnie_shoes(0.032202), skirt(0.032747)\n",
      "Run 5 - MAP: 0.039554\n",
      "Best: drum(0.052197), skirt(0.048698)\n",
      "Worst: trousers(0.032239), minnie_dress(0.032474)\n"
     ]
    }
   ],
   "source": [
    "DistMetric = ['cosine']\n",
    "for run in range(5):\n",
    "    Features = np.random.rand(599, 128)\n",
    "    Id2Label = {}\n",
    "    Id = 0\n",
    "    for Label in FeatureDatabase:\n",
    "        for Image in FeatureDatabase[Label]:\n",
    "            Id2Label[Id] = Label\n",
    "            Id += 1\n",
    "    MAP, CMAP = GetMAP([Features], Id2Label, Metrics=DistMetric)\n",
    "    print(\"Run %d - MAP: %8f\" % (run+1, MAP))\n",
    "    Labels = []\n",
    "    CMAPs = []\n",
    "    for Label in CMAP:\n",
    "        Labels.append(Label)\n",
    "        CMAPs.append(CMAP[Label])\n",
    "    Labels = np.array(Labels)\n",
    "    CMAPs = np.array(CMAPs)\n",
    "    Rank = np.argsort(CMAPs)\n",
    "    print(\"Best: %s(%8f)\" % (Labels[Rank[-1]], CMAPs[Rank[-1]]), end=\"\")\n",
    "    print(\", %s(%8f)\" % (Labels[Rank[-2]], CMAPs[Rank[-2]]))\n",
    "    print(\"Worst: %s(%8f)\" % (Labels[Rank[0]], CMAPs[Rank[0]]), end=\"\")\n",
    "    print(\", %s(%8f)\" % (Labels[Rank[1]], CMAPs[Rank[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Features\n",
    "Here, we experiment with color features <br>\n",
    "(Checkout GenerateFeautreDatabase.ipynb and Features.py for details of each feature)\n",
    "\n",
    "We experement with 5 different color codecs:\n",
    "- RGB\n",
    "- Gray\n",
    "- HSV\n",
    "- YUV\n",
    "- Lab\n",
    "\n",
    "And also 5 different features:\n",
    "- Global/Local color histogram: \n",
    "- Global/Local color moment:\n",
    "- Color auto-correlogram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Histograms\n",
    "- First quantize the colors, then calculate histograms\n",
    "- Local means that we cut the image into grids, and calculate histogram for each grid\n",
    "- Reference: [Robust image retrieval based on color histogram of local feature regions](https://link.springer.com/article/10.1007/s11042-009-0362-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.216819 - Time: 0.178556s\n",
      "Best: garment(0.430642), sprite(0.371505)\n",
      "Worst: nba_jersey(0.054858), chair(0.082266)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global RGB Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.227421 - Time: 1.085099s\n",
      "Best: goggles(0.480197), gge_snack(0.423427)\n",
      "Worst: nba_jersey(0.061249), trousers(0.074155)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local RGB Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.147758 - Time: 0.193506s\n",
      "Best: minnie_dress(0.416588), garment(0.369363)\n",
      "Worst: nba_jersey(0.043021), trousers(0.045867)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global Gray Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.196801 - Time: 0.738027s\n",
      "Best: goggles(0.579366), sprite(0.437721)\n",
      "Worst: nba_jersey(0.057353), trousers(0.062184)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local Gray Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.244082 - Time: 0.202458s\n",
      "Best: minnie_dress(0.489047), korean_snack(0.441652)\n",
      "Worst: nba_jersey(0.049035), trousers(0.057826)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global HSV Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.252586 - Time: 2.307830s\n",
      "Best: sprite(0.560629), goggles(0.469974)\n",
      "Worst: trousers(0.056851), nba_jersey(0.057878)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local HSV Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.205076 - Time: 0.204488s\n",
      "Best: minnie_dress(0.554774), goggles(0.453895)\n",
      "Worst: trousers(0.043189), nba_jersey(0.045316)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global YUV Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.248130 - Time: 2.020626s\n",
      "Best: sprite(0.579795), goggles(0.550990)\n",
      "Worst: trousers(0.047736), nba_jersey(0.049910)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local YUV Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.202028 - Time: 0.211468s\n",
      "Best: minnie_dress(0.437601), goggles(0.431584)\n",
      "Worst: nba_jersey(0.043520), trousers(0.051446)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global Lab Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.247574 - Time: 2.030536s\n",
      "Best: sprite(0.563474), aloe_vera_gel(0.550830)\n",
      "Worst: nba_jersey(0.046656), trousers(0.065445)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local Lab Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.108482 - Time: 0.210436s\n",
      "Best: garment(0.281315), goggles(0.217116)\n",
      "Worst: nba_jersey(0.043861), aloe_vera_gel(0.054339)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global RGB Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.100542 - Time: 0.499691s\n",
      "Best: garment(0.222236), gge_snack(0.187341)\n",
      "Worst: nba_jersey(0.036981), drum(0.036991)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local RGB Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.084076 - Time: 0.173535s\n",
      "Best: garment(0.190709), goggles(0.190580)\n",
      "Worst: clock(0.039349), nba_jersey(0.045735)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global Gray Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.093259 - Time: 0.443842s\n",
      "Best: garment(0.186177), gge_snack(0.161884)\n",
      "Worst: bicycle(0.036053), drum(0.036238)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local Gray Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.120536 - Time: 0.218442s\n",
      "Best: skirt(0.268911), goggles(0.236657)\n",
      "Worst: nba_jersey(0.049542), trousers(0.052583)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global HSV Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.104022 - Time: 0.486698s\n",
      "Best: aloe_vera_gel(0.277636), korean_snack(0.245633)\n",
      "Worst: ice_cream(0.038129), drum(0.041457)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local HSV Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.114469 - Time: 0.173568s\n",
      "Best: goggles(0.273059), minnie_dress(0.253180)\n",
      "Worst: clock(0.035845), bicycle(0.042445)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global YUV Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.081900 - Time: 0.492682s\n",
      "Best: garment(0.187043), aloe_vera_gel(0.173401)\n",
      "Worst: drum(0.024146), bicycle(0.029019)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local YUV Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.117041 - Time: 0.184500s\n",
      "Best: minnie_dress(0.337858), garment(0.244982)\n",
      "Worst: bicycle(0.033868), clock(0.037392)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Global Lab Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.089716 - Time: 0.559494s\n",
      "Best: aloe_vera_gel(0.296906), garment(0.225646)\n",
      "Worst: drum(0.021298), bicycle(0.027063)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local Lab Moment\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Auto-Correlogram\n",
    "- Auto-correlogram calculate the probability that a color appears near(in some distance) itself\n",
    "- The probabilities were approximated by only counting the 8 pixels in the 8 directions to reduce computation \n",
    "- Reference: [Image Indexing Using Color Correlograms](http://www.cs.cornell.edu/~rdz/Papers/Huang-CVPR97.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.280854 - Time: 0.286270s\n",
      "Best: women_clothes(0.721712), minnie_dress(0.671403)\n",
      "Worst: chair(0.058344), leather_purse(0.103197)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"RGB Auto-Correlogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.167133 - Time: 0.227401s\n",
      "Best: minnie_dress(0.623290), garment(0.404961)\n",
      "Worst: nba_jersey(0.035346), clock(0.040869)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Gray Auto-Correlogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.302070 - Time: 0.282244s\n",
      "Best: minnie_dress(0.748849), korean_snack(0.710094)\n",
      "Worst: chair(0.068773), bicycle(0.116661)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HSV Auto-Correlogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.243780 - Time: 0.287266s\n",
      "Best: minnie_dress(0.667765), sprite(0.512101)\n",
      "Worst: chair(0.060503), nba_jersey(0.065502)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"YUV Auto-Correlogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.233564 - Time: 0.283269s\n",
      "Best: minnie_dress(0.584799), women_clothes(0.486346)\n",
      "Worst: chair(0.053759), clock(0.056109)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Lab Auto-Correlogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texture/Shape Features \n",
    "Here, we experiment with texture and shape features <br>\n",
    "(Checkout GenerateFeautreDatabase.ipynb and Features.py for details of each feature)\n",
    "\n",
    "We use gray images for calculating all the features below, <br>\n",
    "since we experimented with colors in the above experiments already\n",
    "\n",
    "We experiment with 8 different features:\n",
    "- Gabor extracted features\n",
    "- Gabor global/local histogram\n",
    "- (Grid) Local binary pattern\n",
    "- (Pyramid) Histogram of oriented gradients\n",
    "- Shape Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gabor Extracted Features\n",
    "- First, the gray scale image is passed through several gabor filters\n",
    "- Then extract energy, amplitude mean, and amplitude variance for each filtered image\n",
    "- Reference: [Texture Features for Browsing and Retrieval of Image Data](https://www.csie.ntu.edu.tw/~b97053/paper/Texture%20features%20for%20browsing%20and%20retrieval%20of%20image%20data.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.128974 - Time: 0.208448s\n",
      "Best: garment(0.402665), gge_snack(0.396663)\n",
      "Worst: clock(0.043924), glasses(0.046348)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Gabor Features\"], \n",
    "              MetricList=['cosine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gabor Global/Local Histogram\n",
    "- First, the gray scale image is passed through several gabor filters\n",
    "- Then calculate the color histogram for each filtered image\n",
    "- Local means that we cut the image into grids, and calculate histogram for each grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.152167 - Time: 0.433875s\n",
      "Best: garment(0.509958), minnie_dress(0.337481)\n",
      "Worst: tennis_ball(0.050089), glasses(0.050118)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Gabor Global Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.184137 - Time: 17.507202s\n",
      "Best: goggles(0.486365), garment(0.426358)\n",
      "Worst: trousers(0.072763), glasses(0.078090)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Gabor Local Histogram\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Binary Pattern\n",
    "- First generate the local binary pattern with skimage.feature.local_binary_pattern\n",
    "- Then calculate it's histogram\n",
    "- Grid means that we cut the image into grids, and calculate histogram for each grid\n",
    "- Reference: [Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns](http://www.ee.oulu.fi/research/mvmp/mvg/files/pdf/pdf_94.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.118357 - Time: 0.219415s\n",
      "Best: goggles(0.273743), garment(0.250648)\n",
      "Worst: tennis_ball(0.044047), clock(0.050103)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Local Binary Pattern\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.174267 - Time: 1.154907s\n",
      "Best: goggles(0.454712), garment(0.375908)\n",
      "Worst: orange(0.065158), drum(0.073253)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Grid Local Binary Pattern\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Oriented Gradients\n",
    "- Generated by skimage.feature.hog\n",
    "- PHOG is Pyramid + HOG\n",
    "    - Different resolutions of HOG are weighted by its inverse\n",
    "    - Since we use cityblock as distance metric, the weights are applied when generating features (Shouldn't do it this way in reality lol)\n",
    "- Reference: [Histograms of Oriented Gradients for Human Detection](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.233068 - Time: 1.161912s\n",
      "Best: goggles(0.660422), gge_snack(0.536469)\n",
      "Worst: drum(0.087050), glasses(0.091062)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HOG\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.275521 - Time: 20.433430s\n",
      "Best: gge_snack(0.797922), goggles(0.663505)\n",
      "Worst: glasses(0.091843), ice_cream(0.135433)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"PHOG\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape Index\n",
    "- Generate by skimage.feature.shape_index\n",
    "- Calculate Histogram after on shape index transformed image\n",
    "- Use different sigmas then concatenate\n",
    "- Reference: [Surface shape and curvature scales](https://www.sciencedirect.com/science/article/pii/026288569290076F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.160053 - Time: 0.213428s\n",
      "Best: goggles(0.394650), garment(0.369391)\n",
      "Worst: aloe_vera_gel(0.052802), glasses(0.061207)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Shape Index\"], \n",
    "              MetricList=['cityblock'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Features\n",
    "Here, we experiment with local features <br>\n",
    "(Checkout GenerateFeautreDatabase.ipynb and Features.py for details of each feature)\n",
    "\n",
    "Similarily, we only use gray images in the experiments below\n",
    "\n",
    "We experiment with 3 different features:\n",
    "- SIFT descriptors\n",
    "- Dense SIFT descriptors\n",
    "- Pyramid SIFT descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT\n",
    "- SIFT is descriptors on detected keypoints\n",
    "- Dense SIFT is to first Cut image into grids, then compute SIFT descriptors on each grid\n",
    "- Cut image into different sizes of grids, then compute dense SIFT for each size\n",
    "- Pyrimad is to cut the image into different sizes of grids and compute SIFT descriptors on each grid\n",
    "- The `match` distance metric for SIFT is by using FLANN(Fast Library for Approximate Nearest Neighbors) to find the top 2 nearest neighbor for each descriptor, then count the number os matches that passes Lowe's ratio test (the nearest neighbor must be a lot closer than the second nearest neighbor to be counted as a \"good match\"), finally multiply by -1 (simply because I use min-favor distance)  \n",
    "- Reference: [Distinctive Image Features from Scale-Invariant Keypoints](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.241059 - Time: 2751.956974s\n",
      "Best: gge_snack(0.996176), korean_snack(0.930700)\n",
      "Worst: ice_cream(0.028946), glasses(0.029925)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Google Drive\\Cognitive Computing\\HW2\\utils.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Distances[i] = ((D.T - Mean) / Var).T\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"SIFT\"], \n",
    "              MetricList=['match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.235383 - Time: 5666.827838s\n",
      "Best: gge_snack(0.543353), cup(0.504652)\n",
      "Worst: ice_cream(0.035214), trousers(0.060200)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Dense SIFT\"], \n",
    "              MetricList=['match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.208704 - Time: 34795.211326s\n",
      "Best: gge_snack(0.525038), aloe_vera_gel(0.485464)\n",
      "Worst: ice_cream(0.036362), trousers(0.055615)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"Pyramid SIFT\"], \n",
    "              MetricList=['match'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion\n",
    "\n",
    "Here, we try to fuse different methods above, and try to get better results\n",
    "\n",
    "We calculate each feature's seperately, and calculate the distances with the provided metric <br>\n",
    "Then, we normalize the distances of each feature to 0-mean-1-norm <br>\n",
    "Finally, we weighted sum the distances up if `WeightList` is provided, otherwize, simply sum them up\n",
    "\n",
    "Since there are too much combinations, we only tested a few by choosing the best performed methods, as well as looking at the best and worse categories of each method (Finding diverse and good features !)\n",
    "\n",
    "We experimented this part in gradient descend fashion, which is by adding the best feature and adjusting the weights one at a time, and try to get the best weights for each feature, kinda like overfitting on the dataset in some sort, shouldn't be done in this way in reality though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.302070 - Time: 0.366021s\n",
      "Best: minnie_dress(0.748849), korean_snack(0.710094)\n",
      "Worst: chair(0.068773), bicycle(0.116661)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HSV Auto-Correlogram\"], \n",
    "              MetricList=['cityblock'],\n",
    "              WeightList=[1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.321625 - Time: 0.479729s\n",
      "Best: minnie_dress(0.795488), women_clothes(0.742243)\n",
      "Worst: chair(0.063828), nba_jersey(0.120994)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HSV Auto-Correlogram\", \"RGB Auto-Correlogram\"], \n",
    "              MetricList=['cityblock', 'cityblock'],\n",
    "              WeightList=[1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.397548 - Time: 20.997874s\n",
      "Best: gge_snack(0.765450), women_clothes(0.721041)\n",
      "Worst: chair(0.125682), glasses(0.176486)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HSV Auto-Correlogram\", \"RGB Auto-Correlogram\", \"PHOG\"], \n",
    "              MetricList=['cityblock', 'cityblock', 'cityblock'],\n",
    "              WeightList=[1.0, 1.0, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.405850 - Time: 21.784767s\n",
      "Best: gge_snack(0.756555), women_clothes(0.711493)\n",
      "Worst: chair(0.132190), nba_jersey(0.172422)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HSV Auto-Correlogram\", \"RGB Auto-Correlogram\", \"PHOG\", \"Local HSV Histogram\"], \n",
    "              MetricList=['cityblock', 'cityblock', 'cityblock', 'cityblock'],\n",
    "              WeightList=[1.0, 1.0, 0.4, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.405896 - Time: 39.265033s\n",
      "Best: gge_snack(0.756625), women_clothes(0.711263)\n",
      "Worst: chair(0.132332), nba_jersey(0.172485)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HSV Auto-Correlogram\", \"RGB Auto-Correlogram\", \"PHOG\", \"Local HSV Histogram\", \"Gabor Local Histogram\"], \n",
    "              MetricList=['cityblock', 'cityblock', 'cityblock', 'cityblock', 'cityblock'],\n",
    "              WeightList=[1.0, 1.0, 0.4, 0.4, 0.06])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.407771 - Time: 3079.882237s\n",
      "Best: gge_snack(0.780173), women_clothes(0.708421)\n",
      "Worst: chair(0.143022), glasses(0.160553)\n"
     ]
    }
   ],
   "source": [
    "RunExperiment(FeatureDatabase, \n",
    "              FeatureList=[\"HSV Auto-Correlogram\", \"RGB Auto-Correlogram\", \"PHOG\", \"Local HSV Histogram\", \"Gabor Local Histogram\", \"SIFT\"], \n",
    "              MetricList=['cityblock', 'cityblock', 'cityblock', 'cityblock', 'cityblock', 'match'],\n",
    "              WeightList=[1.0, 1.0, 0.4, 0.4, 0.06, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Here, we organize the results into tables <br>\n",
    "We summarize the MAP, best 2 categories, worst 2 categories, and the inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Hypothesis\n",
    "\n",
    "The null hypothesis is features generated randomly, thus only the MAP matters here <br>\n",
    "We could see that the MAP is pretty stable around 0.04\n",
    "\n",
    "| Categories v.s. Methods | MAP | Best 2 Categories | Worst 2 Categories | Inference Time\n",
    "|:---------:|:-----:|:-------:|:-----:|:-----:|\n",
    "| Null Hypothesis Run 1 | 0.041509 | Irrelevant | Irrelevant | Irrelevant |\n",
    "| Null Hypothesis Run 2 | 0.040547 | Irrelevant | Irrelevant | Irrelevant |\n",
    "| Null Hypothesis Run 3 | 0.041753 | Irrelevant | Irrelevant | Irrelevant |\n",
    "| Null Hypothesis Run 4 | 0.041563 | Irrelevant | Irrelevant | Irrelevant |\n",
    "| Null Hypothesis Run 5 | 0.039554 | Irrelevant | Irrelevant | Irrelevant |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Features\n",
    "\n",
    "We experimented with 5 different color codecs (RGB, Gray, HSV, YUV, Lab) <br>\n",
    "Here are some findings about these color codecs:\n",
    "- HSV performs the best regardless of what method we choose\n",
    "- Gray performs the worst overall, since it contains the least information\n",
    "- YUV and Lab have very simillar results\n",
    "\n",
    "We also experimented with 5 different methods, here are the findings:\n",
    "- Auto-correlogram performs the best, since it not only contain color features, but also the spatial distribution of the colors\n",
    "- Local histograms performed better than global histograms, since it also contains some spatial information. However, since the spatial feature it contains is computed simply by cutting image into grids, when image shift or rotate, it might lead to worse result, but the database we test in this homework is pretty stable, most images are in about the same position and rotaion, thus local histogram didn't lead to disastrous results\n",
    "- In color moments, grid method actually made results worse, which is pretty surprising, maybe because after cutting into grids, the statistics of moments became too biased\n",
    "\n",
    "Findings about best and worse categories:\n",
    "- We could see that sprite, minnie_dress, korean_snack, goggles, garments, aloe_vera_gel performed the best\n",
    "    - By looking at the images, we could see that these categories all have simmilar in-class color distribution\n",
    "    - Except for goggles, I think the reason goggles perform well in colors is because of the consistant white background\n",
    "- We could see that nba_jersey, trousers, chair performs the worse:\n",
    "    - By looking at the images, we could see that these categories all have very diverse in-class color distribution \n",
    "\n",
    "| Categories v.s. Methods | MAP | Best 2 Categories | Worst 2 Categories | Inference Time\n",
    "|:---------:|:-----:|:-------:|:-----:|:-----:|\n",
    "| Global Color Histogram (RGB) | 0.216819 | garment(0.430642), sprite(0.371505) | nba_jersey(0.054858), chair(0.082266) | 0.178556s|\n",
    "| Global Color Histogram (Gray) | 0.147758 | minnie_dress(0.416588), garment(0.369363) | nba_jersey(0.043021), trousers(0.045867) | 0.193506s |\n",
    "| Global Color Histogram (HSV) | **0.244082** | minnie_dress(0.489047), korean_snack(0.441652) | nba_jersey(0.049035), trousers(0.057826) | 0.202458s |\n",
    "| Global Color Histogram (YUV) | 0.205076 | minnie_dress(0.554774), goggles(0.453895) | trousers(0.043189), nba_jersey(0.045316) | 0.204488s |\n",
    "| Global Color Histogram (Lab) | 0.202028 | minnie_dress(0.437601), goggles(0.431584) | nba_jersey(0.043520), trousers(0.051446) | 0.211468s |\n",
    "| Local Color Histogram (RGB) | 0.227421 | goggles(0.480197), gge_snack(0.423427) | nba_jersey(0.061249), trousers(0.074155) | 1.085099s |\n",
    "| Local Color Histogram (Gray) | 0.196801 | goggles(0.579366), sprite(0.437721) | nba_jersey(0.057353), trousers(0.062184) | 0.738027s |\n",
    "| Local Color Histogram (HSV) | **0.252586** | sprite(0.560629), goggles(0.469974) | trousers(0.056851), nba_jersey(0.057878) | 2.307830s |\n",
    "| Local Color Histogram (YUV) | 0.248130 | sprite(0.579795), goggles(0.550990) | trousers(0.047736), nba_jersey(0.049910) | 2.020626s |\n",
    "| Local Color Histogram (Lab) | 0.247575 | sprite(0.563474), aloe_vera_gel(0.550830) | nba_jersey(0.046681), trousers(0.065445) | 2.009626s |\n",
    "| Global Color Moments (RGB) | 0.108482 | garment(0.281315), goggles(0.217116) | nba_jersey(0.043861), aloe_vera_gel(0.054339) | 0.210436s |\n",
    "| Global Color Moments (Gray) | 0.084076 | garment(0.190709), goggles(0.190580) | clock(0.039349), nba_jersey(0.045735) | 0.173535s |\n",
    "| Global Color Moments (HSV) | **0.120536** | skirt(0.268911), goggles(0.236657) | nba_jersey(0.049542), trousers(0.052583) | 0.218442s |\n",
    "| Global Color Moments (YUV) | 0.114469 | goggles(0.273059), minnie_dress(0.253180) | clock(0.035845), bicycle(0.042445) | 0.173568s |\n",
    "| Global Color Moments (Lab) | 0.117041 | minnie_dress(0.337858), garment(0.244982) | bicycle(0.033868), clock(0.037392) | 0.184500s |\n",
    "| Local Color Moments (RGB) | 0.100542 | garment(0.222236), gge_snack(0.187341) | nba_jersey(0.036981), drum(0.036991) | 0.499691s |\n",
    "| Local Color Moments (Gray) | 0.093259 | garment(0.186177), gge_snack(0.161884) | bicycle(0.036053), drum(0.036238) | 0.443842s |\n",
    "| Local Color Moments (HSV) | **0.104022** | aloe_vera_gel(0.277636), korean_snack(0.245633) | ice_cream(0.038129), drum(0.041457) | 0.486698s |\n",
    "| Local Color Moments (YUV) | 0.081900 | garment(0.187043), aloe_vera_gel(0.173401) | drum(0.024146), bicycle(0.029019) | 0.492682s |\n",
    "| Local Color Moments (Lab) | 0.089716 | aloe_vera_gel(0.296906), garment(0.225646) | drum(0.021298), bicycle(0.027063) | 0.559494s |\n",
    "| Color Auto-Correlogram (RGB) | 0.280854 | women_clothes(0.721712), minnie_dress(0.671403) | chair(0.058344), leather_purse(0.103197) | 0.286270s |\n",
    "| Color Auto-Correlogram (Gray) | 0.167133 | minnie_dress(0.623290), garment(0.404961) | nba_jersey(0.035346), clock(0.040869) | 0.227401s |\n",
    "| Color Auto-Correlogram (HSV) | **0.302070** | minnie_dress(0.748849), korean_snack(0.710094) | chair(0.068773), bicycle(0.116661) | 0.282244s |\n",
    "| Color Auto-Correlogram (YUV) | 0.243780 | minnie_dress(0.667765), sprite(0.512101) | chair(0.060503), nba_jersey(0.065502) | 0.287266s |\n",
    "| Color Auto-Correlogram (Lab) | 0.233564 | minnie_dress(0.584799), women_clothes(0.486346) | chair(0.053759), clock(0.056109) | 0.283269s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Texture / Shape Features\n",
    "\n",
    "We experimented with 8 different methods, here are some findings: <br>\n",
    "- HOG performed the best, and adding pyramid structure made it improved quite a bit\n",
    "- goggles performed the best in most methods, maybe due to it's consistant shape, but also might be it's consistant white background again\n",
    "- garment and gge_snack also performed well in texture and shapes, maybe due to the shape and texture of the clothe for garment and the weird texture (the noodle) for gge_snack\n",
    "- glasses seems to be performing the worst in texture/shape feature\n",
    "    - Texture of the background interferes a lot\n",
    "    - Shape of glasses aren't consistant\n",
    "    - The girl wearing the glass might also intefere a lot\n",
    "    - Why is there a picture of a cyclist wearing sunglasses in this category??? The majority of this image is the bicycle and the cyclist, I wouldn't want my search of glasses have this image in the results \n",
    "\n",
    "| Categories v.s. Methods | MAP | Best 2 Categories | Worst 2 Categories | Inference Time\n",
    "|:---------:|:-----:|:-------:|:-----:|:-----:|\n",
    "| Gabor Extrcted Features | 0.128974 | garment(0.402665), gge_snack(0.396663) | clock(0.043924), glasses(0.046348) | 0.208448s |\n",
    "| Gabor Global Histogram | 0.152167 | garment(0.509958), minnie_dress(0.337481) | tennis_ball(0.050089), glasses(0.050118) | 0.433875s |\n",
    "| Gabor Local Histogram | 0.184137 | goggles(0.486365), garment(0.426358) | trousers(0.072763), glasses(0.078090) | 17.527202s |\n",
    "| Local Binary Pattern | 0.118357 | goggles(0.273743), garment(0.250648) | tennis_ball(0.044047), clock(0.050103) | 0.219415s |\n",
    "| Grid Local Binary Pattern | 0.174267 | goggles(0.454712), garment(0.375908) | orange(0.065158), drum(0.073253) | 1.154907s |\n",
    "| Histogram of oriented gradients | 0.233608 | goggles(0.660422), gge_snack(0.536469) | drum(0.087050), glasses(0.091062) | 1.161912s |\n",
    "| Pyramid Histogram of oriented gradients | **0.275521** | gge_snack(0.797922), goggles(0.663505) | glasses(0.091843), ice_cream(0.135433) | 20.433430s |\n",
    "| Shape Index | 0.160053 | goggles(0.394650), garment(0.369391) | aloe_vera_gel(0.052802), glasses(0.061207) | 0.213428s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Feature\n",
    "\n",
    "We experimented with 3 different methods, here are some findings:\n",
    "- The overall MAP for SIFT isn't good, but if we check on the best categories, we could see that SIFT performed almost perfect on certain categories, bad bad on some other\n",
    "- Dense SIFT and Pyramid Dense SIFT performed ok as well, but not as good as SIFT with keypoint detection, maybe because of too much noise when calculating the descriptors\n",
    "- SIFT takes a very long time to inference, since it cannot simply use cityblock or cosine distance metrics, but have to try to match the descriptors, even after using KD-tree with ANN, we still need about 10 seconds for 1 query, even on such a small database as ours\n",
    "- If we limit the number of keypoints to detect for SIFT, the performance will drop a bit, but will speed up about quit a lot (about 30% speed up when restriced number of keypoints to 512)\n",
    "- The matching process could actually be well parallelize, but I didn't spend much time implementing it\n",
    "- gge_snack performed extremely well with SIFT, since the words(張君雅小妹妹) are very good keypoints for SIFT descriptors, and almost always matches correctly on the words\n",
    "- The logo on aloe_vera_gel as well as the words are also the reason why SIFT did so well on it\n",
    "- goggles and oranges performed well because no good descriptors could be found on these images\n",
    "\n",
    "| Categories v.s. Methods | MAP | Best 2 Categories | Worst 2 Categories | Inference Time\n",
    "|:---------:|:-----:|:-------:|:-----:|:-----:|\n",
    "| SIFT | **0.241059** | gge_snack(0.996176), korean_snack(0.930700) | ice_cream(0.028946), glasses(0.029925) | 2751.956974s |\n",
    "| Dense SIFT | 0.235383 | gge_snack(0.543353), cup(0.504652) | ice_cream(0.035214), trousers(0.060200) | 5666.827838s |\n",
    "| Pyramid Dense SIFT | 0.208704 | gge_snack(0.525038), aloe_vera_gel(0.485464) | ice_cream(0.036362), trousers(0.055615) | 34795.211326s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fusion\n",
    "\n",
    "Fusing increases the performance by a lot, since different features could complement each other <br>\n",
    "Adding SIFT didn't improve much, probably because the categories SIFT done well is already doing pretty well\n",
    "\n",
    "| Categories v.s. Methods | MAP | Best 2 Categories | Worst 2 Categories | Inference Time |\n",
    "|:---------:|:-----:|:-------:|:-----:|:-----:|\n",
    "| Fusion (without SIFT) | 0.405896 | gge_snack(0.756625), women_clothes(0.711263) | chair(0.132332), nba_jersey(0.172485) | 39.265033s |\n",
    "| Fusion (with SIFT) | 0.407771 | gge_snack(0.780173), women_clothes(0.708421) | chair(0.143022), glasses(0.160553) | 3079.882237s |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
